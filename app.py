import logging
import os
import uuid

import gradio as gr

from llmriddles.questions import QuestionExecutor
from llmriddles.questions import list_ordered_questions

_QUESTION_SESSIONS = {}
count = 0
_QUESTIONS = list_ordered_questions()
_LANG = os.environ.get('QUESTION_LANG', 'cn')
assert _LANG in ['cn', 'en'], _LANG
_LLM = os.environ.get('QUESTION_LLM', 'chatgpt')
assert _LLM in ['chatgpt', 'chatglm', 'mistral-7b'], _LLM
_LLM_KEY = os.environ.get('QUESTION_LLM_KEY', None)
_DEBUG = os.environ.get('DEBUG', 'false').lower() == 'true'

if _DEBUG:
    logging.getLogger().setLevel(logging.INFO)
else:
    logging.getLogger().setLevel(logging.WARNING)
if _LANG == "cn":
    title = "å®Œè›‹ï¼æˆ‘è¢« LLM æ‹¿æäº†"
    requirement_ph = """
    <h2 style="color: #6d28d9;"> æ¬¢è¿æ¥åˆ° LLM Riddles! </h2>
    <h4> ä½ å°†é€šè¿‡æœ¬æ¸¸æˆå¯¹å¤§è¯­è¨€æ¨¡å‹äº§ç”Ÿæ›´æ·±åˆ»çš„ç†è§£ã€‚åœ¨æœ¬æ¸¸æˆä¸­ï¼Œä½ éœ€è¦æ„é€ ä¸€ä¸ªæç»™è¯­è¨€å¤§æ¨¡å‹çš„é—®é¢˜ï¼Œä½¿å¾—å®ƒå›å¤çš„ç­”æ¡ˆç¬¦åˆé¢˜ç›®è¦æ±‚ã€‚ç‚¹å‡»<i>\"ä¸‹ä¸€é¢˜\"</i> å³å¯å¼€å§‹æ¸¸æˆã€‚</h4>
    """
    requirement_label = "æ¸¸æˆé¡»çŸ¥/è¯´æ˜"
    question_ph = "ä½ å¯¹å¤§è¯­è¨€æ¨¡å‹çš„æé—®ï¼ˆä¾‹å¦‚ï¼šè¯·ä½ è¾“å‡º1+1=3ï¼‰"
    question_label = "ç©å®¶æé—®æ "
    answer_ph = "å¤§è¯­è¨€æ¨¡å‹çš„å›ç­”"
    answer_label = "å¤§è¯­è¨€æ¨¡å‹å›ç­”æ "
    submit_label = "æäº¤"
    next_label = "ä¸‹ä¸€é¢˜"
    api_ph = "ä½ ä¸ªäººçš„å¤§è¯­è¨€æ¨¡å‹ API Key (ä¾‹å¦‚ï¼šChatGPT)"
    api_label = "API key"
    predict_label = "ç»“æœæ­£ç¡®æ€§"
    explanation_label = "ç»“æœè¯¦ç»†è§£é‡Š"
    game_cleared_label = "<h2 style='color: #6d28d9;'>ç¥è´ºï¼ä½ å·²æˆåŠŸé€šå…³ï¼</h2>"
    correct_label = "æ­£ç¡®"
    wrong_label = "é”™è¯¯"
    api_error_info = "è¯·åœ¨æäº¤é—®é¢˜ä¹‹å‰å…ˆè¾“å…¥ä½ çš„ API Key"
    try_again_label = "å†ç©ä¸€æ¬¡"
    select_label = "é€‰æ‹©å…³å¡ï¼ˆæŠ•æœºå–å·§éœ€è°¨æ…ï¼‰"
    title_markdown = """
    <div align="center">
        <img src="https://raw.githubusercontent.com/opendilab/LLMRiddles/main/llmriddles/assets/banner.svg" width="80%" height="20%" alt="Banner Image">
    </div>
    <h2 style="text-align: center; color: black;"><a href="https://github.com/OpenDILab/LLMRiddles"> ğŸ­LLM Riddlesï¼šå®Œè›‹ï¼æˆ‘è¢« LLM æ‹¿æäº†</a></h2>
    <strong><h5 align="center"> å…¶ä»–åœ¨çº¿ç¤ºä¾‹ï¼šä¸­æ–‡åœ¨çº¿è¯•ç©ç‰ˆæœ¬<a href="https://openxlab.org.cn/apps/detail/OpenDILab/LLMRiddlesChatGLMCN">ï¼ˆOpenXLabï¼‰</a> | ä¸­æ–‡åœ¨çº¿è¯•ç©ç‰ˆæœ¬<a href="https://huggingface.co/spaces/OpenDILabCommunity/LLMRiddlesChatGLMCN">ï¼ˆHugging Faceï¼‰</a> <h5></strong>
    <strong><h5 align="center"> æ›´å¤šä¸åŒè¯­è¨€æ¨¡å‹çš„åœ¨çº¿è¯•ç© demo å¯ä»¥è®¿é—® GitHub<a href="https://github.com/OpenDILab/LLMRiddles">æºä»£ç ä»“åº“</a>è·å–<h5></strong>
    <h5 align="center"> å¦‚æœä½ å–œæ¬¢è¿™ä¸ªé¡¹ç›®ï¼Œè¯·ç»™æˆ‘ä»¬åœ¨ GitHub ç‚¹ä¸ª star âœ¨ <a href="https://github.com/OpenDILab/LLMRiddles"> ä»£ç ä»“åº“ä¼ é€é—¨ </a> ã€‚æˆ‘ä»¬å°†ä¼šæŒç»­ä¿æŒæ›´æ–°ã€‚å†æ¬¡æ„Ÿè°¢æ¸¸æˆ<a href="https://www.zhihu.com/people/haoqiang-fan"> åŸä½œè€… </a>çš„å¥‡æ€å¦™æƒ³ï¼  </h5>
    <strong><h5 align="center">æ³¨æ„ï¼šç®—æ³•æ¨¡å‹çš„è¾“å‡ºå¯èƒ½åŒ…å«ä¸€å®šçš„éšæœºæ€§ã€‚ç›¸å…³ç»“æœä¸ä»£è¡¨ä»»ä½•å¼€å‘è€…å’Œç›¸å…³ AI æœåŠ¡çš„æ€åº¦å’Œæ„è§ã€‚æœ¬é¡¹ç›®å¼€å‘è€…ä¸å¯¹ç”Ÿæˆç»“æœä½œä»»ä½•ä¿è¯ï¼Œä»…ä¾›å¨±ä¹ã€‚<h5></strong>
    """
    tos_markdown = """
    ### ä½¿ç”¨æ¡æ¬¾
    ç©å®¶ä½¿ç”¨æœ¬æœåŠ¡é¡»åŒæ„ä»¥ä¸‹æ¡æ¬¾ï¼š
    è¯¥æœåŠ¡æ˜¯ä¸€é¡¹æ¢ç´¢æ€§ç ”ç©¶é¢„è§ˆç‰ˆï¼Œä»…ä¾›éå•†ä¸šç”¨é€”ã€‚å®ƒä»…æä¾›æœ‰é™çš„å®‰å…¨æªæ–½ï¼Œå¹¶å¯èƒ½ç”Ÿæˆä»¤äººåæ„Ÿçš„å†…å®¹ã€‚ä¸å¾—å°†å…¶ç”¨äºä»»ä½•éæ³•ã€æœ‰å®³ã€æš´åŠ›ã€ç§æ—ä¸»ä¹‰ç­‰ç›®çš„ã€‚è¯¥æœåŠ¡å¯èƒ½ä¼šæ”¶é›†ç©å®¶å¯¹è¯æ•°æ®ä»¥ä¾›æœªæ¥ç ”ç©¶ä¹‹ç”¨ã€‚
    å¦‚æœæ‚¨çš„æ¸¸ç©ä½“éªŒæœ‰ä¸ä½³ä¹‹å¤„ï¼Œè¯·å‘é€é‚®ä»¶è‡³ opendilab@pjlab.org.cn ï¼ æˆ‘ä»¬å°†åˆ é™¤ç›¸å…³ä¿¡æ¯ï¼Œå¹¶ä¸æ–­æ”¹è¿›è¿™ä¸ªé¡¹ç›®ã€‚
    ä¸ºäº†è·å¾—æœ€ä½³ä½“éªŒï¼Œè¯·ä½¿ç”¨å°å¼ç”µè„‘è¿›è¡Œæ­¤é¢„è§ˆç‰ˆæ¸¸æˆï¼Œå› ä¸ºç§»åŠ¨è®¾å¤‡å¯èƒ½ä¼šå½±å“å¯è§†åŒ–æ•ˆæœã€‚
    **ç‰ˆæƒæ‰€æœ‰ 2023 OpenDILabã€‚**
    """
elif _LANG == "en":
    title = "LLM Riddles: Oops! Rolling in LLM."
    requirement_ph = """
    <h2 style="color: #6d28d9;">Welcome to LLM Riddles! </h2>
    <h4> In this game, you'll gain a deeper understanding of language models. Your challenge is to create a question to ask a language model in a way that the answer it provides meets specific criteria. Click <i>\'Next\'</i> to Start</h4>
    """
    requirement_label = "Game Requirements"
    question_ph = "Your Question for LLM (e.g. Please print 1+1=3)"
    question_label = "Question"
    answer_ph = "Answer From LLM"
    answer_label = "Answer"
    submit_label = "Submit"
    next_label = "Next"
    api_ph = "Your API Key (e.g. ChatGPT)"
    api_label = "API key"
    predict_label = "Correctness"
    explanation_label = "Explanation"
    game_cleared_label = "<h2 style='color: #6d28d9;'>Congratulations!</h2>"
    correct_label = "Correct"
    wrong_label = "Wrong"
    api_error_info = "Please Enter API Key Before Submitting Question."
    try_again_label = "Try Again"
    select_label = "Select level"
    title_markdown = """
    <div align="center">
        <img src="https://raw.githubusercontent.com/opendilab/LLMRiddles/main/llmriddles/assets/banner.svg" width="80%" height="20%" alt="Banner Image">
    </div>
    <h2 style="text-align: center; color: black;"><a href="https://github.com/OpenDILab/LLMRiddles"> ğŸ­LLM Riddles: Oops! Rolling in LLM.</a></h2>
    <h5 align="center"> If you like our project, please give us a star âœ¨ on GitHub for latest update <a href="https://github.com/OpenDILab/LLMRiddles"> (Code Link) </a>. Thanks for the interesting idea of the original game <a href="https://www.zhihu.com/people/haoqiang-fan"> author </a>.  </h5>
    <strong><h5 align="center">Notice: The output is generated by algorithm scheme and may involve some randomness. It does not represent the attitudes and opinions of any developers and AI services in this project. We do not make any guarantees about the generated content.<h5></strong>
    """
    tos_markdown = """
    ### Terms of use
    By using this service, players are required to agree to the following terms:
    The service is a research preview intended for non-commercial use only. It only provides limited safety measures and may generate offensive content. It must not be used for any illegal, harmful, violent, racist, or sexual purposes. The service may collect user dialogue data for future research.
    Please send email to opendilab@pjlab.org.cn if you get any inappropriate answer! We will delete those and keep improving our moderator.
    For an optimal experience, please use desktop computers for this demo, as mobile devices may compromise its quality.
    **Copyright 2023 OpenDILab.**
    """
else:
    raise KeyError("invalid _LANG: {}".format(_LANG))


def _need_api_key():
    return (_LLM == 'chatgpt' or _LLM == 'chatglm') and _LLM_KEY is None


def _get_api_key_cfgs(api_key):
    if _LLM == 'chatgpt':
        return {'api_key': api_key}
    elif _LLM == 'chatglm':
        return {'api_key': api_key}
    else:
        return {}


if __name__ == '__main__':
    with gr.Blocks(title=title, theme='ParityError/Interstellar') as demo:
        gr.Markdown(title_markdown)

        with gr.Row():
            gr_requirement = gr.HTML(value=requirement_ph, label=requirement_label)
        with gr.Row():
            with gr.Column():
                gr_question = gr.TextArea(placeholder=question_ph, label=question_label)
                gr_api_key = gr.Text(placeholder=api_ph, label=api_label, type='password', visible=_need_api_key())
                with gr.Row():
                    gr_submit = gr.Button(submit_label, interactive=False)
                    gr_next = gr.Button(next_label)
                with gr.Row():
                    gr_select = gr.Radio(
                        choices=[(QuestionExecutor(q, _LANG).question_name, i) for i, q in enumerate(_QUESTIONS)],
                        label=select_label
                    )

            with gr.Column():
                gr_uuid = gr.Text(value='', visible=False)
                gr_predict = gr.Label(label=predict_label)
                gr_answer = gr.TextArea(label=answer_label, lines=3)
                gr_explanation = gr.TextArea(label=explanation_label, lines=1)
        gr.Markdown(tos_markdown)

        def _postprocess_question_text(question_text):
            if _LANG == 'cn':
                idx = question_text.find('ï¼Œ')
                question_title = question_text[:idx]
                former, latter = question_title.split('ï¼ˆ')
                question_title = former + 'ï¼š' + latter[:-1]
                question_text = f"<h2 style='color: #6d28d9;'>{question_title}</h2><h4>{question_text[idx+1:]}</h4>"
            elif _LANG == 'en':
                idx = question_text.find(',')
                question_text = f"<h2 style='color: #6d28d9;'>{question_text[:idx]}</h2><h4>{question_text[idx+1:]}</h4>"
            return question_text


        def _radio_select(uuid_, select_qid):
            global count
            if not uuid_:
                uuid_ = str(uuid.uuid4())
                count += 1
                logging.info(f'Player {count} starts the game now')
            global _QUESTION_SESSIONS
            if uuid_ not in _QUESTION_SESSIONS:
                _QUESTION_SESSIONS[uuid_] = set(), select_qid
            else:
                _exists, _ = _QUESTION_SESSIONS[uuid_]
                _QUESTION_SESSIONS[uuid_] = _exists, select_qid

            executor = QuestionExecutor(_QUESTIONS[select_qid], _LANG)
            question_text = _postprocess_question_text(executor.question_text)
            return question_text, '', '', {}, '', \
                gr.Button(submit_label, interactive=True), \
                gr.Button(next_label, interactive=False), \
                uuid_

        gr_select.select(
            _radio_select,
            inputs=[gr_uuid, gr_select],
            outputs=[
                gr_requirement, gr_question, gr_answer,
                gr_predict, gr_explanation, gr_submit, gr_next, gr_uuid,
            ],
        )


        def _next_question(uuid_):
            global count
            if not uuid_:
                uuid_ = str(uuid.uuid4())
                count += 1
                logging.info(f'Player {count} starts the game now')
            global _QUESTION_SESSIONS
            if uuid_ in _QUESTION_SESSIONS:
                _exists, _qid = _QUESTION_SESSIONS[uuid_]
            else:
                _exists, _qid = set(), -1
            _qid += 1
            _QUESTION_SESSIONS[uuid_] = _exists, _qid

            if _qid >= len(_QUESTIONS):
                del _QUESTION_SESSIONS[uuid_]
                logging.info(f'Player {count} has passed the game now')
                return game_cleared_label, '', '', {}, '', \
                    gr.Button(submit_label, interactive=False), \
                    gr.Button(try_again_label, interactive=True), \
                    '', \
                    gr.Radio(
                        choices=[(QuestionExecutor(q, _LANG).question_name, i) for i, q in enumerate(_QUESTIONS)],
                        label=select_label
                    )
            else:
                executor = QuestionExecutor(_QUESTIONS[_qid], _LANG)
                question_text = _postprocess_question_text(executor.question_text)
                return question_text, '', '', {}, '', \
                    gr.Button(submit_label, interactive=True), \
                    gr.Button(next_label, interactive=False), \
                    uuid_, \
                    gr.Radio(
                        choices=[(QuestionExecutor(q, _LANG).question_name, i) for i, q in enumerate(_QUESTIONS)],
                        value=_qid,
                        label=select_label,
                    )


        gr_next.click(
            fn=_next_question,
            inputs=[gr_uuid],
            outputs=[
                gr_requirement, gr_question, gr_answer,
                gr_predict, gr_explanation, gr_submit, gr_next,
                gr_uuid, gr_select,
            ],
        )


        def _submit_answer(qs_text: str, api_key: str, uuid_: str):
            global _QUESTION_SESSIONS
            if _need_api_key() and not api_key:
                raise gr.Error(api_error_info)

            _exists, _qid = _QUESTION_SESSIONS[uuid_]
            executor = QuestionExecutor(
                _QUESTIONS[_qid], _LANG,
                llm=_LLM, llm_cfgs=_get_api_key_cfgs(api_key) if _need_api_key() else {'api_key': _LLM_KEY}
            )
            answer_text, correctness, explanation = executor.check(qs_text)
            labels = {correct_label: 1.0} if correctness else {wrong_label: 1.0}
            if correctness:
                _QUESTION_SESSIONS[uuid_] = (_exists | {_qid}), _qid
                return answer_text, labels, explanation, gr.Button(next_label, interactive=True), uuid_
            else:
                return answer_text, labels, explanation, gr.Button(next_label, interactive=False), uuid_


        gr_submit.click(
            _submit_answer,
            inputs=[gr_question, gr_api_key, gr_uuid],
            outputs=[gr_answer, gr_predict, gr_explanation, gr_next, gr_uuid],
        )

    concurrency = int(os.environ.get('CONCURRENCY', os.cpu_count()))
    favicon_path = os.path.join(os.path.dirname(__file__), 'llmriddles', 'assets', 'avatar.png')
    demo.queue().launch(max_threads=concurrency, favicon_path=favicon_path, share=True)
